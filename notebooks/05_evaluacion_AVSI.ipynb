{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82760ad1",
   "metadata": {},
   "source": [
    "# 05 · Evaluación Final — AVSI\n",
    "**Artificial Vision Stacking Inspection** · *2025-10-22*\n",
    "\n",
    "Consolida resultados de entrenamiento y prueba, y genera gráficas finales para el informe:\n",
    "- Carga métricas de `03_modelado` (history, matriz de confusión, reporte).\n",
    "- Integra resultados de `04_optimizacion` (mejor configuración).\n",
    "- Produce un **resumen ejecutivo** con KPIs clave.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c57f4c",
   "metadata": {},
   "source": [
    "## 1. Rutas y archivos esperados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63055352",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ROOT = Path('.').resolve()\n",
    "RESULTS_DIR = ROOT / 'results' / 'metrics'\n",
    "FIG_DIR = ROOT / 'results' / 'figures'\n",
    "MODELS_DIR = ROOT / 'models'\n",
    "\n",
    "files = {\n",
    "    'history': RESULTS_DIR / 'history.csv',\n",
    "    'cm': RESULTS_DIR / 'confusion_matrix.csv',\n",
    "    'report': RESULTS_DIR / 'classification_report.csv',\n",
    "    'summary': RESULTS_DIR / 'summary.json',\n",
    "    'grid': RESULTS_DIR / 'grid_results.csv'\n",
    "}\n",
    "files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c09937",
   "metadata": {},
   "source": [
    "## 2. Carga de resultados y visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f57b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception as e:\n",
    "        print('[Aviso]', e)\n",
    "        return pd.DataFrame()\n",
    "\n",
    "hist = safe_read_csv(files['history'])\n",
    "cm = safe_read_csv(files['cm'])\n",
    "report = safe_read_csv(files['report'])\n",
    "grid = safe_read_csv(files['grid'])\n",
    "\n",
    "# history\n",
    "if not hist.empty:\n",
    "    plt.figure()\n",
    "    plt.plot(hist['train_loss'], label='train_loss')\n",
    "    plt.plot(hist['val_loss'], label='val_loss')\n",
    "    plt.title('Pérdida — entrenamiento')\n",
    "    plt.xlabel('Época'); plt.ylabel('Loss'); plt.legend()\n",
    "    plt.savefig(FIG_DIR / 'final_loss.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(hist['train_acc'], label='train_acc')\n",
    "    plt.plot(hist['val_acc'], label='val_acc')\n",
    "    plt.title('Exactitud — entrenamiento')\n",
    "    plt.xlabel('Época'); plt.ylabel('Accuracy'); plt.legend()\n",
    "    plt.savefig(FIG_DIR / 'final_accuracy.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('[Aviso] No se encontró history.csv (ejecuta 03_modelado).')\n",
    "\n",
    "# matriz de confusión\n",
    "if not cm.empty:\n",
    "    plt.figure()\n",
    "    plt.imshow(cm.values, interpolation='nearest')\n",
    "    plt.title('Matriz de confusión (test)')\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('Predicción'); plt.ylabel('Real')\n",
    "    plt.savefig(FIG_DIR / 'final_confusion_matrix.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print('[Aviso] No se encontró confusion_matrix.csv.')\n",
    "\n",
    "# reporte clasificación (opcional)\n",
    "if not report.empty:\n",
    "    display(report.head())\n",
    "else:\n",
    "    print('[Aviso] No se encontró classification_report.csv.')\n",
    "\n",
    "# mejores configs de grid\n",
    "if not grid.empty:\n",
    "    display(grid.head())\n",
    "else:\n",
    "    print('[Aviso] No se encontró grid_results.csv (ejecuta 04_optimizacion).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707701cb",
   "metadata": {},
   "source": [
    "## 3. Resumen ejecutivo (KPIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63456844",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary = {}\n",
    "if files['summary'].exists():\n",
    "    with open(files['summary'], 'r') as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "kpis = {\n",
    "    'best_val_acc': summary.get('best_val_acc', None),\n",
    "    'test_accuracy': summary.get('test_accuracy', None),\n",
    "    'num_classes': len(summary.get('classes', [])) if summary.get('classes') else None,\n",
    "}\n",
    "kpis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee39d33",
   "metadata": {},
   "source": [
    "## 4. Comparativa vs. baseline (opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9dae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si dispones de un CSV 'baseline.csv' con columnas: metric,value\n",
    "BASELINE = RESULTS_DIR / 'baseline.csv'\n",
    "if BASELINE.exists():\n",
    "    base = pd.read_csv(BASELINE)\n",
    "    print('Baseline:'); display(base)\n",
    "else:\n",
    "    print('[Info] No hay baseline.csv — puedes crearlo con tus métricas iniciales (dataset_100).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6250e1c9",
   "metadata": {},
   "source": [
    "## 5. Exportar reporte simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2317cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report_txt = RESULTS_DIR / 'final_report.txt'\n",
    "lines = []\n",
    "lines.append('AVSI — Evaluación Final\\n')\n",
    "lines.append('=======================\\n\\n')\n",
    "lines.append('KPIs:\\n')\n",
    "for k, v in kpis.items():\n",
    "    lines.append(f\"- {k}: {v}\\n\")\n",
    "lines.append('\\nArchivos generados en results/figures y results/metrics.\\n')\n",
    "\n",
    "with open(report_txt, 'w', encoding='utf-8') as f:\n",
    "    f.writelines(lines)\n",
    "\n",
    "str(report_txt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f0cec2",
   "metadata": {},
   "source": [
    "## 6. Notas\n",
    "- Para métricas de **detección** (mAP/IoU), integra un detector (por ejemplo, Faster R-CNN/YOLO) y calcula métricas específicas.\n",
    "- Este notebook consolida **clasificación**; ajusta según tu setup final.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
